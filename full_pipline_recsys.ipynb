{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import implicit\n",
    "import dask_ml.model_selection as dcv\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import featuretools as ft\n",
    "from airflow import AirflowException\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import implicit\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = dd.read_csv(\"D:/ab_data_old.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>utc_event_time</th>\n",
       "      <th>utc_event_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>ecom.price100</th>\n",
       "      <th>ecom.qty</th>\n",
       "      <th>ecom.nm</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: drop-duplicates-agg, 3 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              platform utc_event_time utc_event_date user_id event_type ecom.price100 ecom.qty ecom.nm main_category sub_category\n",
       "npartitions=1                                                                                                                    \n",
       "                object         object         object  object     object        object   object  object        object       object\n",
       "                   ...            ...            ...     ...        ...           ...      ...     ...           ...          ...\n",
       "Dask Name: drop-duplicates-agg, 3 graph layers"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old['utc_event_date'] = df_old['utc_event_date'].astype('datetime64')\n",
    "df_old['utc_event_time'] = df_old['utc_event_time'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_list(s):\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old['ecom.price100'] = df_old['ecom.price100'].apply(parse_list, meta=('ecom.price100', 'object'))\n",
    "df_old['ecom.qty'] = df_old['ecom.qty'].apply(parse_list, meta=('ecom.qty', 'object'))\n",
    "# Функция для подсчета суммарной стоимости заказа\n",
    "def calculate_full_price(prices, quantities):\n",
    "    return sum([price * qty for price, qty in zip(prices, quantities)])\n",
    "\n",
    "df_old['full_price'] = df_old.apply(lambda row: calculate_full_price(row['ecom.price100'], row['ecom.qty']), axis=1, meta=('full_price', 'f8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = dd.read_csv(\"D:/ab_data_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df_old = df_old.sample(frac=0.001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df_new = df_new.sample(frac=0.001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df_old = sampled_df_old.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df_new = sampled_df_new.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([sampled_df_old, sampled_df_new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.replace(to_replace='\\[', value='{', regex=True)\n",
    "result = result.replace(to_replace='\\]', value='}', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>utc_event_time</th>\n",
       "      <th>utc_event_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>ecom.price100</th>\n",
       "      <th>ecom.qty</th>\n",
       "      <th>ecom.nm</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 20:37:38+00:00</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>147534996411926129189354456304486601363</td>\n",
       "      <td>ec.add_to_cart</td>\n",
       "      <td>{69300}</td>\n",
       "      <td>{1}</td>\n",
       "      <td>{286456731318525039062227138237012117405}</td>\n",
       "      <td>{193601878183246116301078047479003646325}</td>\n",
       "      <td>{339478044799599646652421530298088607414}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 11:25:21+00:00</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>19364707531800924819468646855893647645</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>{59100}</td>\n",
       "      <td>{1}</td>\n",
       "      <td>{303656313937557151080734452891496101101}</td>\n",
       "      <td>{71402771771545593484075637726561164864}</td>\n",
       "      <td>{63611650087129534491462483505745531385}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 19:50:57+00:00</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>340190641677221836115070922869104104545</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>{93300}</td>\n",
       "      <td>{1}</td>\n",
       "      <td>{21432984705629339384250371538407603708}</td>\n",
       "      <td>{144086449872839020031157148875692321280}</td>\n",
       "      <td>{305734460618872236820852415916833016155}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 16:54:20+00:00</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>288215427478547986941748692904103889492</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>{9700}</td>\n",
       "      <td>{1}</td>\n",
       "      <td>{132939881791584002164092610759999415143}</td>\n",
       "      <td>{45117301157169820192891250731273658842}</td>\n",
       "      <td>{32128344998495328435874083790015283258}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 16:55:22+00:00</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>256760310340863130243758005505267323721</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>{587500}</td>\n",
       "      <td>{1}</td>\n",
       "      <td>{78961424905234892818452146684548497012}</td>\n",
       "      <td>{154366424108017296963249370561478064618}</td>\n",
       "      <td>{60270833747106288434434595877071461453}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  platform             utc_event_time utc_event_date  \\\n",
       "0      iOS  2023-07-31 20:37:38+00:00     2023-07-31   \n",
       "1      iOS  2023-07-31 11:25:21+00:00     2023-07-31   \n",
       "2      iOS  2023-07-31 19:50:57+00:00     2023-07-31   \n",
       "3      iOS  2023-07-31 16:54:20+00:00     2023-07-31   \n",
       "4      iOS  2023-07-31 16:55:22+00:00     2023-07-31   \n",
       "\n",
       "                                   user_id      event_type ecom.price100  \\\n",
       "0  147534996411926129189354456304486601363  ec.add_to_cart       {69300}   \n",
       "1   19364707531800924819468646855893647645    ec.view_item       {59100}   \n",
       "2  340190641677221836115070922869104104545    ec.view_item       {93300}   \n",
       "3  288215427478547986941748692904103889492    ec.view_item        {9700}   \n",
       "4  256760310340863130243758005505267323721    ec.view_item      {587500}   \n",
       "\n",
       "  ecom.qty                                    ecom.nm  \\\n",
       "0      {1}  {286456731318525039062227138237012117405}   \n",
       "1      {1}  {303656313937557151080734452891496101101}   \n",
       "2      {1}   {21432984705629339384250371538407603708}   \n",
       "3      {1}  {132939881791584002164092610759999415143}   \n",
       "4      {1}   {78961424905234892818452146684548497012}   \n",
       "\n",
       "                               main_category  \\\n",
       "0  {193601878183246116301078047479003646325}   \n",
       "1   {71402771771545593484075637726561164864}   \n",
       "2  {144086449872839020031157148875692321280}   \n",
       "3   {45117301157169820192891250731273658842}   \n",
       "4  {154366424108017296963249370561478064618}   \n",
       "\n",
       "                                sub_category  \n",
       "0  {339478044799599646652421530298088607414}  \n",
       "1   {63611650087129534491462483505745531385}  \n",
       "2  {305734460618872236820852415916833016155}  \n",
       "3   {32128344998495328435874083790015283258}  \n",
       "4   {60270833747106288434434595877071461453}  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "platform          object\n",
       "utc_event_time    object\n",
       "utc_event_date    object\n",
       "user_id           object\n",
       "event_type        object\n",
       "ecom.price100     object\n",
       "ecom.qty          object\n",
       "ecom.nm           object\n",
       "main_category     object\n",
       "sub_category      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = pd.read_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['utc_event_date'] = sampled_df['utc_event_date'].astype('datetime64')\n",
    "sampled_df['utc_event_time'] = sampled_df['utc_event_time'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_train, global_test = dcv.train_test_split(sampled_df, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Делим global_train на first_level_train и first_level_test\n",
    "first_level_train, first_level_test = dcv.train_test_split(global_train, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_train_pd = first_level_train.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>utc_event_time</th>\n",
       "      <th>utc_event_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>ecom.price100</th>\n",
       "      <th>ecom.qty</th>\n",
       "      <th>ecom.nm</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>full_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175398</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 19:57:00</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>290564369032320414383090094780208210767</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[27000]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[248897785758177919271711105194391560319]</td>\n",
       "      <td>[169229459350063279254734619770911789504]</td>\n",
       "      <td>[170335703378959694218902789929304334287]</td>\n",
       "      <td>27000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133680</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 19:53:08</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>221245115738888070119440997732641183661</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[29400]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[193838509435602725175392345741904390249]</td>\n",
       "      <td>[194927924485076366241852915388643859829]</td>\n",
       "      <td>[147896236488183456659210880425294371958]</td>\n",
       "      <td>29400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233230</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 12:16:15</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>112045341699515244156726421138689862008</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[295200]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[200262166635294611395809918002938948494]</td>\n",
       "      <td>[144086449872839020031157148875692321280]</td>\n",
       "      <td>[245537685737357503556259659767153414300]</td>\n",
       "      <td>295200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21572</th>\n",
       "      <td>Site</td>\n",
       "      <td>2023-07-31 19:53:23</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>334586506734689881617709847877108181574</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[99000]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[105630530349412454148770909775635583518]</td>\n",
       "      <td>[144086449872839020031157148875692321280]</td>\n",
       "      <td>[120029211906102602042345900801057134592]</td>\n",
       "      <td>99000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155898</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 20:23:56</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>87940016043212373438488945181177271322</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[23600]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[210511309526241460729667084190424065717]</td>\n",
       "      <td>[45117301157169820192891250731273658842]</td>\n",
       "      <td>[276255514729783517826214466182227430458]</td>\n",
       "      <td>23600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       platform      utc_event_time utc_event_date  \\\n",
       "175398      iOS 2023-07-31 19:57:00     2023-07-31   \n",
       "133680      iOS 2023-07-31 19:53:08     2023-07-31   \n",
       "233230      iOS 2023-07-31 12:16:15     2023-07-31   \n",
       "21572      Site 2023-07-31 19:53:23     2023-07-31   \n",
       "155898      iOS 2023-07-31 20:23:56     2023-07-31   \n",
       "\n",
       "                                        user_id    event_type ecom.price100  \\\n",
       "175398  290564369032320414383090094780208210767  ec.view_item       [27000]   \n",
       "133680  221245115738888070119440997732641183661  ec.view_item       [29400]   \n",
       "233230  112045341699515244156726421138689862008  ec.view_item      [295200]   \n",
       "21572   334586506734689881617709847877108181574  ec.view_item       [99000]   \n",
       "155898   87940016043212373438488945181177271322  ec.view_item       [23600]   \n",
       "\n",
       "       ecom.qty                                    ecom.nm  \\\n",
       "175398      [1]  [248897785758177919271711105194391560319]   \n",
       "133680      [1]  [193838509435602725175392345741904390249]   \n",
       "233230      [1]  [200262166635294611395809918002938948494]   \n",
       "21572       [1]  [105630530349412454148770909775635583518]   \n",
       "155898      [1]  [210511309526241460729667084190424065717]   \n",
       "\n",
       "                                    main_category  \\\n",
       "175398  [169229459350063279254734619770911789504]   \n",
       "133680  [194927924485076366241852915388643859829]   \n",
       "233230  [144086449872839020031157148875692321280]   \n",
       "21572   [144086449872839020031157148875692321280]   \n",
       "155898   [45117301157169820192891250731273658842]   \n",
       "\n",
       "                                     sub_category  full_price  \n",
       "175398  [170335703378959694218902789929304334287]       27000  \n",
       "133680  [147896236488183456659210880425294371958]       29400  \n",
       "233230  [245537685737357503556259659767153414300]      295200  \n",
       "21572   [120029211906102602042345900801057134592]       99000  \n",
       "155898  [276255514729783517826214466182227430458]       23600  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_level_train_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "platform                  object\n",
       "utc_event_time    datetime64[ns]\n",
       "utc_event_date    datetime64[ns]\n",
       "user_id                   object\n",
       "event_type                object\n",
       "ecom.price100             object\n",
       "ecom.qty                  object\n",
       "ecom.nm                   object\n",
       "main_category             object\n",
       "sub_category              object\n",
       "full_price                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_level_train_pd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_train_pd = first_level_train_pd.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_train_pd = first_level_train_pd.dropna(subset=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_level_train_pd = first_level_train_pd[first_level_train_pd['ecom.nm'].apply(lambda x: x != '[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kamil\\PycharmProjects\\pythonProject\\RecSys\\full_pipline_recsys.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/PycharmProjects/pythonProject/RecSys/full_pipline_recsys.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m cols_to_convert:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/PycharmProjects/pythonProject/RecSys/full_pipline_recsys.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             new_row[col] \u001b[39m=\u001b[39m row[col][i] \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(row[col]) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Kamil/PycharmProjects/pythonProject/RecSys/full_pipline_recsys.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         expanded_first_train \u001b[39m=\u001b[39m expanded_first_train\u001b[39m.\u001b[39;49mappend(new_row)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Kamil/PycharmProjects/pythonProject/RecSys/full_pipline_recsys.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m expanded_first_train\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:9768\u001b[0m, in \u001b[0;36mDataFrame.append\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9665\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9666\u001b[0m \u001b[39mAppend rows of `other` to the end of caller, returning a new object.\u001b[39;00m\n\u001b[0;32m   9667\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9758\u001b[0m \u001b[39m4  4\u001b[39;00m\n\u001b[0;32m   9759\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9760\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   9761\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mThe frame.append method is deprecated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   9762\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mand will be removed from pandas in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9765\u001b[0m     stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   9766\u001b[0m )\n\u001b[1;32m-> 9768\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_append(other, ignore_index, verify_integrity, sort)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:9808\u001b[0m, in \u001b[0;36mDataFrame._append\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   9805\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   9806\u001b[0m     to_concat \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m, other]\n\u001b[1;32m-> 9808\u001b[0m result \u001b[39m=\u001b[39m concat(\n\u001b[0;32m   9809\u001b[0m     to_concat,\n\u001b[0;32m   9810\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[0;32m   9811\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[0;32m   9812\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   9813\u001b[0m )\n\u001b[0;32m   9814\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mappend\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m     objs,\n\u001b[0;32m    370\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    378\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m )\n\u001b[1;32m--> 381\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[0;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    618\u001b[0m )\n\u001b[0;32m    619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[0;32m    620\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:233\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    231\u001b[0m     fastpath \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m values\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    232\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 233\u001b[0m     values \u001b[39m=\u001b[39m _concatenate_join_units(join_units, concat_axis, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    234\u001b[0m     fastpath \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39mif\u001b[39;00m fastpath:\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:577\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m    574\u001b[0m     concat_values \u001b[39m=\u001b[39m ensure_block_shape(concat_values, \u001b[39m2\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     concat_values \u001b[39m=\u001b[39m concat_compat(to_concat, axis\u001b[39m=\u001b[39;49mconcat_axis)\n\u001b[0;32m    579\u001b[0m \u001b[39mreturn\u001b[39;00m concat_values\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\concat.py:151\u001b[0m, in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[0;32m    148\u001b[0m             to_concat \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mastype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m to_concat]\n\u001b[0;32m    149\u001b[0m             kinds \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mo\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m--> 151\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate(to_concat, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m    152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m kinds \u001b[39mand\u001b[39;00m result\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    153\u001b[0m     \u001b[39m# GH#39817\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    155\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBehavior when concatenating bool-dtype and numeric-dtype arrays is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated; in a future version these will cast to object dtype \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    161\u001b[0m     )\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Преобразование строк в списки\n",
    "cols_to_convert = ['ecom.price100', 'ecom.qty', 'ecom.nm', 'main_category', 'sub_category']\n",
    "#for col in cols_to_convert:\n",
    "#    first_level_train_pd[col] = first_level_train_pd[col].apply(ast.literal_eval)\n",
    "\n",
    "# Преобразование строк с несколькими элементами в отдельные строки\n",
    "expanded_first_train = pd.DataFrame()\n",
    "for idx, row in first_level_train_pd.iterrows():\n",
    "    max_len = max(len(row[col]) for col in cols_to_convert)\n",
    "    for i in range(max_len):\n",
    "        new_row = row.copy()\n",
    "        for col in cols_to_convert:\n",
    "            new_row[col] = row[col][i] if i < len(row[col]) else None\n",
    "        expanded_first_train = expanded_first_train.append(new_row)\n",
    "\n",
    "expanded_first_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_first_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_first_train.to_csv('expanded_first_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_first_train = pd.read_csv('expanded_first_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_first_train = expanded_first_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing 'user_id'\n",
    "expanded_first_train = expanded_first_train.dropna(subset=['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_first_train = expanded_first_train[expanded_first_train['ecom.nm'].apply(lambda x: x != '[]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание словаря для пользователей и их покупок\n",
    "user_purchases = {}\n",
    "for index, row in expanded_first_train.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    purchase = row['ecom.nm']\n",
    "    if user_id not in user_purchases:\n",
    "        user_purchases[user_id] = []\n",
    "    user_purchases[user_id].append(purchase)\n",
    "\n",
    "# Создание словаря, где ключами будут user_id, а значениями - списки уникальных id товаров\n",
    "user_item_dict = {user: list(set(items)) for user, items in user_purchases.items()}\n",
    "all_items = set(item for items in user_item_dict.values() for item in items)\n",
    "\n",
    "# Создание обратного словаря для быстрого поиска индексов товаров по id\n",
    "item_to_index = {item: index for index, item in enumerate(all_items)}\n",
    "index_to_item = {index: item for item, index in item_to_index.items()}\n",
    "\n",
    "# Создание разреженной матрицы user-item\n",
    "num_users = len(user_item_dict)\n",
    "num_items = len(all_items)\n",
    "\n",
    "data = []\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "\n",
    "for user_index, (user, items) in enumerate(user_item_dict.items()):\n",
    "    for item in items:\n",
    "        data.append(1)\n",
    "        row_indices.append(user_index)\n",
    "        col_indices.append(item_to_index[item])\n",
    "\n",
    "user_item_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(num_users, num_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_val = 34\n",
    "data_conf = (user_item_matrix * alpha_val).astype('double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a model\n",
    "model = implicit.als.AlternatingLeastSquares(factors=200, regularization=0.7, iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "# execute training\n",
    "for _ in tqdm(range(EPOCHS), total=EPOCHS):\n",
    "    model.fit(data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for mapping user IDs to integer indices\n",
    "user_to_index = {user: index for index, user in enumerate(user_item_dict.keys())}\n",
    "index_to_user = {index: user for user, index in user_to_index.items()}\n",
    "# Now modify the recommend function to use this new dictionary\n",
    "def recommend(user_id, model, user_item_matrix, N=10):\n",
    "    # Get the user's row in the matrix\n",
    "    user_index = user_to_index[user_id]\n",
    "    # Get the scores for all items for this user\n",
    "    scores = model.user_factors[user_index] @ model.item_factors.T\n",
    "    # Get the indices of the top N items for this user\n",
    "    top_item_indices = np.argpartition(scores, -N)[-N:]\n",
    "    # Convert these indices back to item IDs\n",
    "    top_item_ids = [index_to_item[index] for index in top_item_indices]\n",
    "    return top_item_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string representation of list to actual list\n",
    "def eval_list(value):\n",
    "    if isinstance(value, str):\n",
    "        return eval(value)\n",
    "    else:\n",
    "        return value  # or any other default value\n",
    "\n",
    "# Convert string representations of lists back into actual lists\n",
    "for col in ['ecom.price100', 'ecom.qty', 'ecom.nm', 'main_category', 'sub_category']:\n",
    "    expanded_first_train[col] = expanded_first_train[col].apply(eval_list)\n",
    "\n",
    "# Create a dictionary for mapping user IDs to integer indices\n",
    "user_to_index = {user: index for index, user in enumerate(user_item_dict.keys())}\n",
    "index_to_user = {index: user for user, index in user_to_index.items()}\n",
    "\n",
    "# Flatten the lists in 'ecom.nm' and 'main_category' columns and create the mapping\n",
    "item_name_mapper = {}\n",
    "for ecom_nm_list, main_category_list in zip(expanded_first_train['ecom.nm'], expanded_first_train['main_category']):\n",
    "    for ecom_nm, main_category in zip(ecom_nm_list, main_category_list):\n",
    "        item_name_mapper[ecom_nm] = main_category\n",
    "\n",
    "# Now modify the recommend function to use this new dictionary\n",
    "def recommend(user_id, model, user_item_matrix, N=10):\n",
    "    # Get the user's row in the matrix\n",
    "    user_index = user_to_index[user_id]\n",
    "    \n",
    "    # Get the scores for all items for this user\n",
    "    scores = model.user_factors[user_index] @ model.item_factors.T\n",
    "    \n",
    "    # Get the indices of the top N items for this user\n",
    "    top_item_indices = np.argpartition(scores, -N)[-N:]\n",
    "    \n",
    "    # Convert these indices back to item IDs\n",
    "    top_item_ids = [index_to_item[index] for index in top_item_indices]\n",
    "    \n",
    "    return top_item_ids\n",
    "\n",
    "# Now we'll generate recommendations for all users in the test set\n",
    "test_user_ids = expanded_first_train['user_id'].unique()\n",
    "recommendations = []\n",
    "\n",
    "for user_id in tqdm(test_user_ids):\n",
    "    top_items = recommend(user_id, model, user_item_matrix)\n",
    "    recommendations.extend([(user_id, item_id) for item_id in top_items])\n",
    "\n",
    "# Convert the recommendations to a DataFrame\n",
    "recs_df = pd.DataFrame(recommendations, columns=['user_id', 'item_id'])\n",
    "\n",
    "# Add a 'rank' column that indicates the rank of each item in the recommendations for each user\n",
    "recs_df['rank'] = recs_df.groupby('user_id').cumcount() + 1\n",
    "\n",
    "# Add a 'title' column that maps each item_id to its title\n",
    "recs_df['main_category'] = recs_df['item_id'].map(item_name_mapper)\n",
    "# Create a dictionary for mapping item IDs to their subtitles (subcategories)\n",
    "item_subtitle_mapper = {}\n",
    "for ecom_nm_list, sub_category_list in zip(['ecom.nm'], expanded_first_train['sub_category']):\n",
    "    for ecom_nm, sub_category in zip(ecom_nm_list, sub_category_list):\n",
    "        item_subtitle_mapper[ecom_nm] = sub_category\n",
    "\n",
    "# Add a 'subtitle' column that maps each item_id to its subtitle\n",
    "recs_df['sub_category'] = recs_df['item_id'].map(item_subtitle_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_df.to_csv('recs_df_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_als = pd.read_csv('recs_df_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_als.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(expanded_first_train, df_als, how='inner', on=['user_id', 'ecom.nm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['day_of_week'] = merged_df['utc_event_date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to category dtypes\n",
    "categorical_cols = ['platform', 'event_type', 'main_category', 'sub_category']\n",
    "for col in categorical_cols:\n",
    "    merged_df[col] = merged_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = merged_df.drop('rank', axis=1)\n",
    "y = merged_df['rank']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CatBoostClassifier\n",
    "model = CatBoostClassifier(\n",
    "    iterations=5000,\n",
    "    learning_rate=0.1,\n",
    "    depth=5,\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='Accuracy',\n",
    "    random_seed=42,\n",
    "    verbose=False,\n",
    "    cat_features=categorical_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "preds_class = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame({\n",
    "    'user_id': user_id,\n",
    "    'ecom.nm': ecom.nm,\n",
    "    'rank': preds_class\n",
    "})\n",
    "\n",
    "# Сохранение DataFrame в файл\n",
    "df_predictions.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, preds_class)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAG для загрузки и подготовки к обучению данных\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "# Функция для подключения к базе данных и извлечения данных\n",
    "def get_data_from_postgres():\n",
    "    # Создание подключения\n",
    "    engine = create_engine('postgresql://postgres:kamilg@158.160.40.22:5432/recsys')\n",
    "\n",
    "    # Запрос SQL для извлечения данных\n",
    "    query = \"SELECT * FROM wildberris_recsys\"\n",
    "\n",
    "    # Использование Dask для выполнения SQL-запроса и загрузки данных в DataFrame\n",
    "    df_old = df.read_sql_table(query, engine)\n",
    "\n",
    "    return df_old\n",
    "\n",
    "# Функции для обработки данных и обучения модели\n",
    "def parse_list(s):\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "def calculate_full_price(prices, quantities):\n",
    "    return sum([price * qty for price, qty in zip(prices, quantities)])\n",
    "\n",
    "def prepare_data():\n",
    "    df_old = get_data_from_postgres()\n",
    "    df_old = df_old.drop_duplicates()\n",
    "    df_old['ecom.price100'] = df_old['ecom.price100'].apply(parse_list)\n",
    "    df_old['ecom.qty'] = df_old['ecom.qty'].apply(parse_list)\n",
    "    df_old['full_price'] = df_old.apply(lambda row: calculate_full_price(row['ecom.price100'], row['ecom.qty']), axis=1)\n",
    "    global_train, global_test = train_test_split(df_old, test_size = 0.3, random_state=42)\n",
    "    first_level_train, first_level_test = train_test_split(global_train, test_size = 0.3, random_state=42)\n",
    "    # Преобразование строк в списки\n",
    "    cols_to_convert = ['ecom.price100', 'ecom.qty', 'ecom.nm', 'main_category', 'sub_category']\n",
    "    # Преобразование строк с несколькими элементами в отдельные строки\n",
    "    expanded_first_train = pd.DataFrame()\n",
    "    for idx, row in first_level_train.iterrows():\n",
    "        for col in cols_to_convert:\n",
    "            if isinstance(row[col], str):\n",
    "                max_len = len(row[col])\n",
    "                for i in range(max_len):\n",
    "                    new_row = row.copy()\n",
    "                    new_row[col] = row[col][i]\n",
    "                    expanded_first_train = expanded_first_train.append(new_row, ignore_index=True)\n",
    "            else:\n",
    "                new_row = row.copy()\n",
    "                expanded_first_train = expanded_first_train.append(new_row, ignore_index=True)\n",
    "    expanded_first_train.reset_index(drop=True, inplace=True)\n",
    "    # Сохранение expanded_first_train в XCom\n",
    "    ti = context['ti']\n",
    "    ti.xcom_push(key='expanded_first_train', value=expanded_first_train)\n",
    "\n",
    "# Определение DAG\n",
    "load_data_dag = DAG(\n",
    "    'load_data',\n",
    "    default_args={\n",
    "        'owner': 'limakg',\n",
    "        'depends_on_past': False,\n",
    "        'start_date': datetime(2023, 9, 22),\n",
    "    },\n",
    "    description='A DAG to load and prepare data',\n",
    "    schedule_interval=None,  # Запускать по требованию\n",
    ")\n",
    "\n",
    "dag = DAG(\n",
    "    'prepare_and_train_model',\n",
    "     default_args=default_args,\n",
    "     description='A DAG to prepare data and train a model',\n",
    "     schedule_interval=timedelta(days=1),\n",
    ")\n",
    "\n",
    "# Определение оператора для подготовки данных\n",
    "prepare_data_operator = PythonOperator(\n",
    "     task_id='prepare_data',\n",
    "     python_callable=prepare_data,\n",
    "     dag=dag,\n",
    ")\n",
    "\n",
    "# Запуск DAG\n",
    "prepare_data_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DAG для обучения модели\n",
    "from airflow import AirflowException\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import implicit\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'limakg',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2023, 9, 22),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'recommendation_model',\n",
    "    default_args=default_args,\n",
    "    description='A DAG for recommendation model training and ranking',\n",
    "    schedule_interval=None,  # Запускать по требованию\n",
    ")\n",
    "\n",
    "# Функция для получения expanded_first_train из XCom\n",
    "def get_expanded_first_train(**context):\n",
    "    ti = context['ti']\n",
    "    expanded_first_train = ti.xcom_pull(task_ids='prepare_and_train_model', key='expanded_first_train')\n",
    "    return expanded_first_train\n",
    "\n",
    "# Функция для подготовки и обучения модели\n",
    "def prepare_and_train_model():\n",
    "    def eval_list(value):\n",
    "        if isinstance(value, str):\n",
    "            return eval(value)\n",
    "        else:\n",
    "            return value \n",
    "        \n",
    "    def recommend(user_id, model, user_item_matrix, N=10):\n",
    "        user_index = user_to_index[user_id]\n",
    "        scores = model.user_factors[user_index] @ model.item_factors.T\n",
    "        top_item_indices = np.argpartition(scores, -N)[-N:]\n",
    "        top_item_ids = [index_to_item[index] for index in top_item_indices]\n",
    "        return top_item_ids\n",
    "\n",
    "    expanded_first_train = get_expanded_first_train()\n",
    "    # Создание словаря для пользователей и их покупок\n",
    "    user_purchases = {}\n",
    "    for index, row in expanded_first_train.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        purchase = row['ecom.nm']\n",
    "        if user_id not in user_purchases:\n",
    "            user_purchases[user_id] = []\n",
    "        user_purchases[user_id].append(purchase)\n",
    "    # Создание словаря, где ключами будут user_id, а значениями - списки уникальных id товаров\n",
    "    user_item_dict = {user: list(set(items)) for user, items in user_purchases.items()}\n",
    "    all_items = set(item for items in user_item_dict.values() for item in items)\n",
    "    # Создание обратного словаря для быстрого поиска индексов товаров по id\n",
    "    item_to_index = {item: index for index, item in enumerate(all_items)}\n",
    "    index_to_item = {index: item for item, index in item_to_index.items()}\n",
    "    # Создание разреженной матрицы user-item\n",
    "    num_users = len(user_item_dict)\n",
    "    num_items = len(all_items)\n",
    "    data = []\n",
    "    row_indices = []\n",
    "    col_indices = []\n",
    "    for user_index, (user, items) in enumerate(user_item_dict.items()):\n",
    "        for item in items:\n",
    "            data.append(1)\n",
    "            row_indices.append(user_index)\n",
    "            col_indices.append(item_to_index[item])\n",
    "    user_item_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(num_users, num_items))\n",
    "    alpha_val = 34\n",
    "    data_conf = (user_item_matrix * alpha_val).astype('double')  \n",
    "    # Инициализация модели\n",
    "    model = implicit.als.AlternatingLeastSquares(factors=200, regularization=0.7, iterations=20)\n",
    "    EPOCHS = 20\n",
    "    # Обучение модели\n",
    "    for _ in tqdm(range(EPOCHS), total=EPOCHS):\n",
    "        model.fit(data_conf) \n",
    "    item_name_mapper = {}\n",
    "    for ecom_nm_list, main_category_list in zip(expanded_first_train['ecom.nm'], expanded_first_train['main_category']):\n",
    "        for ecom_nm, main_category in zip(ecom_nm_list, main_category_list):\n",
    "            item_name_mapper[ecom_nm] = main_category\n",
    "    test_user_ids = expanded_first_train['user_id'].unique()\n",
    "    recommendations = []\n",
    "    for user_id in tqdm(test_user_ids):\n",
    "        top_items = recommend(user_id, model, user_item_matrix)\n",
    "        recommendations.extend([(user_id, item_id) for item_id in top_items])\n",
    "    # Создание датафрейма дял рекомендаций\n",
    "    recs_df = pd.DataFrame(recommendations, columns=['user_id', 'item_id'])\n",
    "    recs_df['rank'] = recs_df.groupby('user_id').cumcount() + 1\n",
    "    recs_df['main_category'] = recs_df['item_id'].map(item_name_mapper)\n",
    "    item_subtitle_mapper = {}\n",
    "    for ecom_nm_list, sub_category_list in zip(['ecom.nm'], expanded_first_train['sub_category']):\n",
    "        for ecom_nm, sub_category in zip(ecom_nm_list, sub_category_list):\n",
    "            item_subtitle_mapper[ecom_nm] = sub_category\n",
    "    recs_df['sub_category'] = recs_df['item_id'].map(item_subtitle_mapper)\n",
    "    context['ti'].xcom_push(key='recs_df', value=recs_df)\n",
    "       \n",
    "# Функция для ранжирования рекомендаций\n",
    "def rank_recommendations():\n",
    "    expanded_first_train = get_expanded_first_train()\n",
    "    ti = context['ti']\n",
    "    recs_df = ti.xcom_pull(task_ids='prepare_and_train_model', key='recs_df')\n",
    "    merged_df = pd.merge(expanded_first_train, df_als, how='inner', on=['user_id', 'ecom.nm'])\n",
    "    merged_df['day_of_week'] = merged_df['utc_event_date'].dt.dayofweek\n",
    "    categorical_cols = ['platform', 'event_type', 'main_category', 'sub_category']\n",
    "    for col in categorical_cols:\n",
    "        merged_df[col] = merged_df[col].astype('category')\n",
    "    X = merged_df.drop('rank', axis=1)\n",
    "    y = merged_df['rank']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    second_level_model = CatBoostClassifier(iterations=5000, \n",
    "                                            learning_rate=0.1, \n",
    "                                            depth=7, \n",
    "                                            loss_function='MultiClass', \n",
    "                                            eval_metric='Accuracy', \n",
    "                                            random_seed=42, \n",
    "                                            verbose=False, \n",
    "                                            cat_features=categorical_cols)\n",
    "    second_level_model.fit(X_train, y_train)\n",
    "    preds_class = model.predict(X_test)\n",
    "    # Создание новой таблицы с user_id, item_id и предсказаниями\n",
    "    catrecs_df = merged_df[['user_id', 'item_id']].copy()\n",
    "    catrecs_df['predictions'] = preds_class\n",
    "    catrecs_df.to_csv('/data/cat_recs.csv', index=False)\n",
    "\n",
    "# Определение оператора для получения expanded_first_train из XCom\n",
    "get_expanded_first_train_operator = PythonOperator(\n",
    "    task_id='get_expanded_first_train',\n",
    "    python_callable=get_expanded_first_train,\n",
    "    provide_context=True,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Определение оператора для подготовки и обучения модели\n",
    "prepare_and_train_model_operator = PythonOperator(\n",
    "    task_id='prepare_and_train_model',\n",
    "    python_callable=prepare_and_train_model,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Определение оператора для ранжирования рекомендаций\n",
    "rank_recommendations_operator = PythonOperator(\n",
    "    task_id='rank_recommendations',\n",
    "    python_callable=rank_recommendations,\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Определение зависимостей между задачами\n",
    "get_expanded_first_train_operator >> prepare_and_train_model_operator\n",
    "prepare_and_train_model_operator >> rank_recommendations_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>utc_event_time</th>\n",
       "      <th>utc_event_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>ecom.price100</th>\n",
       "      <th>ecom.qty</th>\n",
       "      <th>ecom.nm</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 20:37:38</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>147534996411926129189354456304486601363</td>\n",
       "      <td>ec.add_to_cart</td>\n",
       "      <td>[69300]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[286456731318525039062227138237012117405]</td>\n",
       "      <td>[193601878183246116301078047479003646325]</td>\n",
       "      <td>[339478044799599646652421530298088607414]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 11:25:21</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>19364707531800924819468646855893647645</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[59100]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[303656313937557151080734452891496101101]</td>\n",
       "      <td>[71402771771545593484075637726561164864]</td>\n",
       "      <td>[63611650087129534491462483505745531385]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 19:50:57</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>340190641677221836115070922869104104545</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[93300]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[21432984705629339384250371538407603708]</td>\n",
       "      <td>[144086449872839020031157148875692321280]</td>\n",
       "      <td>[305734460618872236820852415916833016155]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 16:54:20</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>288215427478547986941748692904103889492</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[9700]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[132939881791584002164092610759999415143]</td>\n",
       "      <td>[45117301157169820192891250731273658842]</td>\n",
       "      <td>[32128344998495328435874083790015283258]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-07-31 16:55:22</td>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>256760310340863130243758005505267323721</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[587500]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[78961424905234892818452146684548497012]</td>\n",
       "      <td>[154366424108017296963249370561478064618]</td>\n",
       "      <td>[60270833747106288434434595877071461453]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  platform      utc_event_time utc_event_date  \\\n",
       "0      iOS 2023-07-31 20:37:38     2023-07-31   \n",
       "1      iOS 2023-07-31 11:25:21     2023-07-31   \n",
       "2      iOS 2023-07-31 19:50:57     2023-07-31   \n",
       "3      iOS 2023-07-31 16:54:20     2023-07-31   \n",
       "4      iOS 2023-07-31 16:55:22     2023-07-31   \n",
       "\n",
       "                                   user_id      event_type ecom.price100  \\\n",
       "0  147534996411926129189354456304486601363  ec.add_to_cart       [69300]   \n",
       "1   19364707531800924819468646855893647645    ec.view_item       [59100]   \n",
       "2  340190641677221836115070922869104104545    ec.view_item       [93300]   \n",
       "3  288215427478547986941748692904103889492    ec.view_item        [9700]   \n",
       "4  256760310340863130243758005505267323721    ec.view_item      [587500]   \n",
       "\n",
       "  ecom.qty                                    ecom.nm  \\\n",
       "0      [1]  [286456731318525039062227138237012117405]   \n",
       "1      [1]  [303656313937557151080734452891496101101]   \n",
       "2      [1]   [21432984705629339384250371538407603708]   \n",
       "3      [1]  [132939881791584002164092610759999415143]   \n",
       "4      [1]   [78961424905234892818452146684548497012]   \n",
       "\n",
       "                               main_category  \\\n",
       "0  [193601878183246116301078047479003646325]   \n",
       "1   [71402771771545593484075637726561164864]   \n",
       "2  [144086449872839020031157148875692321280]   \n",
       "3   [45117301157169820192891250731273658842]   \n",
       "4  [154366424108017296963249370561478064618]   \n",
       "\n",
       "                                sub_category  \n",
       "0  [339478044799599646652421530298088607414]  \n",
       "1   [63611650087129534491462483505745531385]  \n",
       "2  [305734460618872236820852415916833016155]  \n",
       "3   [32128344998495328435874083790015283258]  \n",
       "4   [60270833747106288434434595877071461453]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = sampled_df.replace(to_replace='\\{', value='[', regex=True)\n",
    "sampled_df = sampled_df.replace(to_replace='\\}', value=']', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_list(s):\n",
    "    try:\n",
    "        return ast.literal_eval(s)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []\n",
    "\n",
    "def calculate_full_price(prices, quantities):\n",
    "    return sum([price * qty for price, qty in zip(prices, quantities)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df['ecom.price100'] = sampled_df['ecom.price100'].apply(parse_list)\n",
    "sampled_df['ecom.qty'] = sampled_df['ecom.qty'].apply(parse_list)\n",
    "sampled_df['full_price'] = sampled_df.apply(lambda row: calculate_full_price(row['ecom.price100'], row['ecom.qty']), axis=1)\n",
    "global_train, global_test = train_test_split(sampled_df, test_size = 0.3, random_state=42)\n",
    "first_level_train, first_level_test = train_test_split(global_train, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_convert = ['ecom.price100', 'ecom.qty', 'ecom.nm', 'main_category', 'sub_category']\n",
    "expanded_rows = []\n",
    "\n",
    "for _, row in first_level_train.iterrows():\n",
    "    for col in cols_to_convert:\n",
    "        values = row[col]\n",
    "        if isinstance(values, str):\n",
    "            values = values.split(',')  \n",
    "            for value in values:\n",
    "                new_row = row.copy()\n",
    "                new_row[col] = value\n",
    "                expanded_rows.append(new_row)\n",
    "\n",
    "expanded_first_train = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Сброс индексов\n",
    "expanded_first_train.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>utc_event_time</th>\n",
       "      <th>utc_event_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>ecom.price100</th>\n",
       "      <th>ecom.qty</th>\n",
       "      <th>ecom.nm</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>full_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-08-23 03:06:47</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>8106861414484471935859141324230668269</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[75400]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[273530001670818705607439351893040279956]</td>\n",
       "      <td>[226036533030553532728399561714766831]</td>\n",
       "      <td>[265090531775281326985201851584148835394]</td>\n",
       "      <td>75400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-08-23 03:06:47</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>8106861414484471935859141324230668269</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[75400]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[273530001670818705607439351893040279956]</td>\n",
       "      <td>[226036533030553532728399561714766831]</td>\n",
       "      <td>[265090531775281326985201851584148835394]</td>\n",
       "      <td>75400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-08-23 03:06:47</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>8106861414484471935859141324230668269</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[75400]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[273530001670818705607439351893040279956]</td>\n",
       "      <td>[226036533030553532728399561714766831]</td>\n",
       "      <td>[265090531775281326985201851584148835394]</td>\n",
       "      <td>75400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-08-04 06:46:47</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>251559053185147917817730628260877000539</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[105900]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[89691438885920276379209640370088598132]</td>\n",
       "      <td>[221726170214372670448724233801986642747]</td>\n",
       "      <td>[201584486745237818981159351885067545516]</td>\n",
       "      <td>105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iOS</td>\n",
       "      <td>2023-08-04 06:46:47</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>251559053185147917817730628260877000539</td>\n",
       "      <td>ec.view_item</td>\n",
       "      <td>[105900]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[89691438885920276379209640370088598132]</td>\n",
       "      <td>[221726170214372670448724233801986642747]</td>\n",
       "      <td>[201584486745237818981159351885067545516]</td>\n",
       "      <td>105900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  platform      utc_event_time utc_event_date  \\\n",
       "0      iOS 2023-08-23 03:06:47     2023-08-23   \n",
       "1      iOS 2023-08-23 03:06:47     2023-08-23   \n",
       "2      iOS 2023-08-23 03:06:47     2023-08-23   \n",
       "3      iOS 2023-08-04 06:46:47     2023-08-04   \n",
       "4      iOS 2023-08-04 06:46:47     2023-08-04   \n",
       "\n",
       "                                   user_id    event_type ecom.price100  \\\n",
       "0    8106861414484471935859141324230668269  ec.view_item       [75400]   \n",
       "1    8106861414484471935859141324230668269  ec.view_item       [75400]   \n",
       "2    8106861414484471935859141324230668269  ec.view_item       [75400]   \n",
       "3  251559053185147917817730628260877000539  ec.view_item      [105900]   \n",
       "4  251559053185147917817730628260877000539  ec.view_item      [105900]   \n",
       "\n",
       "  ecom.qty                                    ecom.nm  \\\n",
       "0      [1]  [273530001670818705607439351893040279956]   \n",
       "1      [1]  [273530001670818705607439351893040279956]   \n",
       "2      [1]  [273530001670818705607439351893040279956]   \n",
       "3      [1]   [89691438885920276379209640370088598132]   \n",
       "4      [1]   [89691438885920276379209640370088598132]   \n",
       "\n",
       "                               main_category  \\\n",
       "0     [226036533030553532728399561714766831]   \n",
       "1     [226036533030553532728399561714766831]   \n",
       "2     [226036533030553532728399561714766831]   \n",
       "3  [221726170214372670448724233801986642747]   \n",
       "4  [221726170214372670448724233801986642747]   \n",
       "\n",
       "                                sub_category  full_price  \n",
       "0  [265090531775281326985201851584148835394]       75400  \n",
       "1  [265090531775281326985201851584148835394]       75400  \n",
       "2  [265090531775281326985201851584148835394]       75400  \n",
       "3  [201584486745237818981159351885067545516]      105900  \n",
       "4  [201584486745237818981159351885067545516]      105900  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_first_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "platform                  object\n",
       "utc_event_time    datetime64[ns]\n",
       "utc_event_date    datetime64[ns]\n",
       "user_id                   object\n",
       "event_type                object\n",
       "ecom.price100             object\n",
       "ecom.qty                  object\n",
       "ecom.nm                   object\n",
       "main_category             object\n",
       "sub_category              object\n",
       "full_price                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_first_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_list(value):\n",
    "    if isinstance(value, str):\n",
    "        return eval(value)\n",
    "    else:\n",
    "        return value \n",
    "        \n",
    "def recommend(user_id, model, user_item_matrix, N=10):\n",
    "    user_index = user_to_index[user_id]\n",
    "    scores = model.user_factors[user_index] @ model.item_factors.T\n",
    "    top_item_indices = np.argpartition(scores, -N)[-N:]\n",
    "    top_item_ids = [index_to_item[index] for index in top_item_indices]\n",
    "    return top_item_ids\n",
    "\n",
    "# Создание словаря для пользователей и их покупок\n",
    "user_purchases = {}\n",
    "for index, row in expanded_first_train.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    purchase = row['ecom.nm']\n",
    "    if user_id not in user_purchases:\n",
    "        user_purchases[user_id] = []\n",
    "    user_purchases[user_id].append(purchase)\n",
    "# Создание словаря, где ключами будут user_id, а значениями - списки уникальных id товаров\n",
    "user_item_dict = {user: list(set(items)) for user, items in user_purchases.items()}\n",
    "all_items = set(item for items in user_item_dict.values() for item in items)\n",
    "# Создание обратного словаря для быстрого поиска индексов товаров по id\n",
    "item_to_index = {item: index for index, item in enumerate(all_items)}\n",
    "index_to_item = {index: item for item, index in item_to_index.items()}\n",
    "# Создание разреженной матрицы user-item\n",
    "num_users = len(user_item_dict)\n",
    "num_items = len(all_items)\n",
    "data = []\n",
    "row_indices = []\n",
    "col_indices = []\n",
    "for user_index, (user, items) in enumerate(user_item_dict.items()):\n",
    "    for item in items:\n",
    "        data.append(1)\n",
    "        row_indices.append(user_index)\n",
    "        col_indices.append(item_to_index[item])\n",
    "user_item_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(num_users, num_items))\n",
    "alpha_val = 34\n",
    "data_conf = (user_item_matrix * alpha_val).astype('double')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c03f53edeb24ca0af8420a7880a1055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:31<00:00, 91.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# Инициализация модели\n",
    "model = implicit.als.AlternatingLeastSquares(factors=200, regularization=0.7, iterations=20)\n",
    "EPOCHS = 1\n",
    "# Обучение модели\n",
    "for _ in tqdm(range(EPOCHS), total=EPOCHS):\n",
    "    model.fit(data_conf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39415/39415 [01:50<00:00, 357.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Создание словаря для отображения ecom_nm в main_category\n",
    "item_name_mapper = {}\n",
    "for ecom_nm_list, main_category_list in zip(expanded_first_train['ecom.nm'], expanded_first_train['main_category']):\n",
    "    if pd.notna(ecom_nm_list) and pd.notna(main_category_list):\n",
    "        for ecom_nm, main_category in zip(ecom_nm_list, main_category_list):\n",
    "            item_name_mapper[ecom_nm] = main_category\n",
    "\n",
    "# Получение уникальных пользовательских идентификаторов\n",
    "test_user_ids = expanded_first_train['user_id'].unique()\n",
    "\n",
    "# Создание словаря для отображения ecom_nm в sub_category\n",
    "item_subtitle_mapper = {}\n",
    "for ecom_nm_list, sub_category_list in zip(expanded_first_train['ecom.nm'], expanded_first_train['sub_category']):\n",
    "    if pd.notna(ecom_nm_list) and pd.notna(sub_category_list):\n",
    "        for ecom_nm, sub_category in zip(ecom_nm_list, sub_category_list):\n",
    "            item_subtitle_mapper[ecom_nm] = sub_category\n",
    "\n",
    "# Создание словаря для отображения user_id в индекс\n",
    "user_to_index = {user_id: index for index, user_id in enumerate(test_user_ids)}\n",
    "\n",
    "# Функция для рекомендации\n",
    "def recommend(user_id, model, user_item_matrix, item_name_mapper, N=10):\n",
    "    user_index = user_to_index.get(user_id)\n",
    "    if user_index is None:\n",
    "        return []\n",
    "    scores = model.user_factors[user_index] @ model.item_factors.T\n",
    "    top_item_indices = np.argpartition(scores, -N)[-N:]\n",
    "    return [item_id for item_id in top_item_indices]\n",
    "\n",
    "# Получение рекомендаций и создание датафрейма\n",
    "recommendations = []\n",
    "for user_id in tqdm(test_user_ids):\n",
    "    top_items = recommend(user_id, model, user_item_matrix, item_name_mapper)\n",
    "    recommendations.extend([(user_id, item_id) for item_id in top_items])\n",
    "\n",
    "recs_df = pd.DataFrame(recommendations, columns=['user_id', 'item_id'])\n",
    "recs_df['rank'] = recs_df.groupby('user_id').cumcount() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecom_nm_to_main_category = {}\n",
    "for index, row in expanded_first_train.iterrows():\n",
    "    ecom_nm_list = row['ecom.nm']\n",
    "    main_category_list = row['main_category']\n",
    "    if pd.notna(ecom_nm_list) and pd.notna(main_category_list):\n",
    "        for ecom_nm, main_category in zip(ecom_nm_list, main_category_list):\n",
    "            ecom_nm_to_main_category[ecom_nm] = main_category\n",
    "\n",
    "ecom_nm_to_sub_category = {}\n",
    "for index, row in expanded_first_train.iterrows():\n",
    "    ecom_nm_list = row['ecom.nm']\n",
    "    sub_category_list = row['sub_category']\n",
    "    if pd.notna(ecom_nm_list) and pd.notna(sub_category_list):\n",
    "        for ecom_nm, sub_category in zip(ecom_nm_list, sub_category_list):\n",
    "            ecom_nm_to_sub_category[ecom_nm] = sub_category\n",
    "recs_df['main_category'] = recs_df['item_id'].map(ecom_nm_to_main_category)\n",
    "recs_df['sub_category'] = recs_df['item_id'].map(ecom_nm_to_sub_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_df = pd.read_csv('catrecs_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recs_df = recs_df.rename(columns={'item_id': 'ecom.nm'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>ecom.nm</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8106861414484471935859141324230668269</td>\n",
       "      <td>20596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8106861414484471935859141324230668269</td>\n",
       "      <td>17029</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8106861414484471935859141324230668269</td>\n",
       "      <td>42966</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8106861414484471935859141324230668269</td>\n",
       "      <td>33636</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8106861414484471935859141324230668269</td>\n",
       "      <td>22562</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 user_id ecom.nm  rank\n",
       "0  8106861414484471935859141324230668269   20596     1\n",
       "1  8106861414484471935859141324230668269   17029     2\n",
       "2  8106861414484471935859141324230668269   42966     3\n",
       "3  8106861414484471935859141324230668269   33636     4\n",
       "4  8106861414484471935859141324230668269   22562     5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Kamil\\PycharmProjects\\pythonProject\\RecSys\\full_pipline_recsys.ipynb Cell 69\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kamil/PycharmProjects/pythonProject/RecSys/full_pipline_recsys.ipynb#Y145sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m X \u001b[39m=\u001b[39m merged_df\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mrank\u001b[39m\u001b[39m'\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Kamil/PycharmProjects/pythonProject/RecSys/full_pipline_recsys.ipynb#Y145sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y \u001b[39m=\u001b[39m merged_df[\u001b[39m'\u001b[39m\u001b[39mrank\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Kamil/PycharmProjects/pythonProject/RecSys/full_pipline_recsys.ipynb#Y145sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m-> 2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[0;32m   2564\u001b[0m )\n\u001b[0;32m   2566\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m   2567\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Kamil\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2233\u001b[0m n_train, n_test \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n_train), \u001b[39mint\u001b[39m(n_test)\n\u001b[0;32m   2235\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2236\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2237\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWith n_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, test_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and train_size=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2238\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39maforementioned parameters.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2240\u001b[0m     )\n\u001b[0;32m   2242\u001b[0m \u001b[39mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "recs_df['ecom.nm'] = recs_df['ecom.nm'].astype(str)\n",
    "merged_df = pd.merge(expanded_first_train, recs_df, how='inner', on=['user_id', 'ecom.nm'])\n",
    "merged_df['day_of_week'] = merged_df['utc_event_date'].dt.dayofweek\n",
    "categorical_cols = ['platform', 'event_type']\n",
    "for col in categorical_cols:\n",
    "    merged_df[col] = merged_df[col].astype('category')\n",
    "X = merged_df.drop('rank', axis=1)\n",
    "y = merged_df['rank']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_model = CatBoostClassifier(iterations=5000, \n",
    "                                        learning_rate=0.1, \n",
    "                                        depth=7, \n",
    "                                        loss_function='MultiClass', \n",
    "                                        eval_metric='Accuracy', \n",
    "                                        random_seed=42, \n",
    "                                        verbose=False, \n",
    "                                        cat_features=categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_model.fit(X_train, y_train)\n",
    "preds_class = model.predict(X_test)\n",
    "# Создание новой таблицы с user_id, item_id и предсказаниями\n",
    "catrecs_df = merged_df[['user_id', 'item_id']].copy()\n",
    "catrecs_df['predictions'] = preds_class\n",
    "catrecs_df.to_csv('cat_recs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "predictions = catrecs_df['predictions']\n",
    "actual_ranks = catrecs_df['rank']\n",
    "mse = mean_squared_error(actual_ranks, predictions)\n",
    "mae = mean_absolute_error(actual_ranks, predictions)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
